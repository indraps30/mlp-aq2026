{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaac7c35-f30d-4d22-a68c-ab54894ea883",
   "metadata": {},
   "source": [
    "# **MLProcess - Air Quality**\n",
    "---\n",
    "**4 - Modeling, Tuning, and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e107f124-542f-414a-a47e-8b686eef79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import yaml\n",
    "import joblib\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.linear_model import LogisticRegression as LGR\n",
    "from sklearn.ensemble import BaggingClassifier as BGC, RandomForestClassifier as RFC, AdaBoostClassifier as ABC, GradientBoostingClassifier as GBC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6dd4c-dc1f-4b4b-a689-582323674104",
   "metadata": {},
   "source": [
    "## **1 - Configuration File**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c36174-cc4d-47f1-ac00-60d9341ff634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load configuration parameter.\n",
    "def load_config(path_config):\n",
    "    \"\"\"\n",
    "    Load the configuration file (config.yaml).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    path_config : str\n",
    "        Configuration file location.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    params : dict\n",
    "        The configuration parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try to load config.yaml file.\n",
    "    try:\n",
    "        with open(path_config, 'r') as file:\n",
    "            params = yaml.safe_load(file)\n",
    "    except FileNotFoundError as err:\n",
    "        raise RuntimeError(f\"Configuration file not found in {path_config}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b9509d7-23a5-4348-a411-6bacda7af00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update configuration parameter.\n",
    "def update_config(key, value, params, path_config):\n",
    "    \"\"\"\n",
    "    Update the configuration parameter values.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    key : str\n",
    "        The key to be updated.\n",
    "\n",
    "    value : any type supported in Python\n",
    "        The updated value.\n",
    "\n",
    "    params : dict\n",
    "        Loaded configuration parameters.\n",
    "\n",
    "    path_config : str\n",
    "        Configuration file location.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    config : dict\n",
    "        Updated configuration parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # To maintain the raw config immutable.\n",
    "    params = params.copy()\n",
    "\n",
    "    # Update the configuration parameters.\n",
    "    params[key] = value\n",
    "\n",
    "    with open(path_config, 'w') as file:\n",
    "        yaml.dump(params, file)\n",
    "\n",
    "    print(f\"Params Updated! \\nKey: {key} \\nValue: {value}\\n\")\n",
    "\n",
    "    # Reload the updated configuration parameters.\n",
    "    config = load_config(path_config)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f48c083-3389-4309-b6f3-648bccfa65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file.\n",
    "PATH_CONFIG = \"../config/config.yaml\"\n",
    "config = load_config(PATH_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3f1a51-ade9-48c4-bd85-c75ebb71a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns_datetime': ['tanggal'],\n",
       " 'columns_int': ['pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max'],\n",
       " 'columns_object': ['stasiun', 'critical', 'category'],\n",
       " 'features': ['stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2'],\n",
       " 'impute_co': 11.0,\n",
       " 'impute_no2': 18.0,\n",
       " 'impute_o3': 29.0,\n",
       " 'impute_pm10': {'BAIK': 28.359154929577464, 'TIDAK BAIK': 55.17809298660362},\n",
       " 'impute_pm25': {'BAIK': 39.827586206896555, 'TIDAK BAIK': 82.38564668769716},\n",
       " 'impute_so2': 35.306404657933044,\n",
       " 'label': 'category',\n",
       " 'label_categories': ['BAIK', 'SEDANG', 'TIDAK SEHAT'],\n",
       " 'label_categories_new': ['BAIK', 'TIDAK BAIK'],\n",
       " 'path_clean_test': ['../data/processed/X_test_clean.pkl',\n",
       "  '../data/processed/y_test_clean.pkl'],\n",
       " 'path_clean_train': ['../data/processed/X_train_clean.pkl',\n",
       "  '../data/processed/y_train_clean.pkl'],\n",
       " 'path_clean_valid': ['../data/processed/X_valid_clean.pkl',\n",
       "  '../data/processed/y_valid_clean.pkl'],\n",
       " 'path_data_joined': '../data/interim/joined_dataset.pkl',\n",
       " 'path_data_raw': '../data/raw/',\n",
       " 'path_data_test': ['../data/interim/X_test.pkl',\n",
       "  '../data/interim/y_test.pkl'],\n",
       " 'path_data_train': ['../data/interim/X_train.pkl',\n",
       "  '../data/interim/y_train.pkl'],\n",
       " 'path_data_valid': ['../data/interim/X_valid.pkl',\n",
       "  '../data/interim/y_valid.pkl'],\n",
       " 'path_data_validated': '../data/interim/validated_data.pkl',\n",
       " 'path_fitted_encoder_label': '../models/label_encoder.pkl',\n",
       " 'path_fitted_encoder_stasiun': '../models/ohe_stasiun.pkl',\n",
       " 'path_fitted_scaler': '../models/scaler.pkl',\n",
       " 'range_co': [-1, 47],\n",
       " 'range_no2': [-1, 65],\n",
       " 'range_o3': [-1, 151],\n",
       " 'range_pm10': [-1, 179],\n",
       " 'range_pm25': [-1, 174],\n",
       " 'range_so2': [-1, 82],\n",
       " 'range_stasiun': ['DKI1 (Bunderan HI)',\n",
       "  'DKI2 (Kelapa Gading)',\n",
       "  'DKI3 (Jagakarsa)',\n",
       "  'DKI4 (Lubang Buaya)',\n",
       "  'DKI5 (Kebon Jeruk) Jakarta Barat']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the configuration parameters.\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89c0e8-7e9f-4473-bcf9-bb13d090878c",
   "metadata": {},
   "source": [
    "## **2 - Load Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33638d6-1c30-4a3c-8491-4fe7750f48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load preprocessed data.\n",
    "def load_data(config, data_conf):\n",
    "    \"\"\"\n",
    "    Load the preprocessed data.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    config : dict\n",
    "        The loaded configuration file.\n",
    "\n",
    "    data_conf : str\n",
    "        The data configuration type.\n",
    "        The value must one of these value: ['train', 'valid', 'test']\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the data_conf is valid.\n",
    "    list_data_conf = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "    if data_conf not in list_data_conf:\n",
    "        raise RuntimeError(f\"The data configuration {data_conf} is invalid.\")\n",
    "    else:\n",
    "        data_conf = str(data_conf)\n",
    "        path = f\"path_clean_{data_conf}\"\n",
    "\n",
    "        X = joblib.load(config[path][0])\n",
    "        y = joblib.load(config[path][1])\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffbd7ff7-9106-44c2-a221-0d7634fb1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "X_train, y_train = load_data(config, \"train\")\n",
    "X_valid, y_valid = load_data(config, \"valid\")\n",
    "X_test, y_test = load_data(config, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935f7b7-8d3c-4fc8-9813-f834ac61140e",
   "metadata": {},
   "source": [
    "## **3 - Training Log**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489ef4f4-cb71-453a-b106-2e23c13cb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to support training log creation.\n",
    "def time_stamp():\n",
    "    return datetime.now()\n",
    "\n",
    "def create_training_log():\n",
    "    logger = {\n",
    "        \"model_name\": [],\n",
    "        \"model_id\": [],\n",
    "        \"training_time\": [],\n",
    "        \"training_date\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"cv_f1\": [],\n",
    "        \"data_configuration\": []\n",
    "    }\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea3888a-3f5a-4aab-976d-ee96af70c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_training_log(current_log, path_log):\n",
    "    \"\"\"\n",
    "    Update the training log.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    current_log : dict\n",
    "        The training log current state.\n",
    "\n",
    "    path_log : str\n",
    "        The directory of training log.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    last_log : dict\n",
    "        The updated training log.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the current log immutable.\n",
    "    current_log = current_log.copy()\n",
    "\n",
    "    # Open the training log file.\n",
    "    try:\n",
    "        with open(path_log, 'r') as file:\n",
    "            last_log = json.load(file)\n",
    "    # If the training log does not exists.\n",
    "    except FileNotFoundError as err:\n",
    "        # Create the new training log.\n",
    "        with open(path_log, 'w') as file:\n",
    "            file.write(\"[]\")\n",
    "\n",
    "        # Reload the current training log.\n",
    "        with open(path_log, 'r') as file:\n",
    "            last_log = json.load(file)\n",
    "\n",
    "    last_log.append(current_log)\n",
    "\n",
    "    # Rewrite the training log with the updated one.\n",
    "    with open(path_log, 'w') as file:\n",
    "        json.dump(last_log, file)\n",
    "\n",
    "    return last_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30717ea5-f9ed-4cae-9b72-375859bd7e5f",
   "metadata": {},
   "source": [
    "## **4 - Model Training**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e54672-28fb-4fb2-8d4d-486475dcf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model object.\n",
    "def create_model_object():\n",
    "    \"\"\"Return a list of model to be fitted.\"\"\"\n",
    "\n",
    "    # Create model object.\n",
    "    knn = KNN()\n",
    "    lgr = LGR()\n",
    "    dtc = DTC()\n",
    "    bgc = BGC()\n",
    "    rfc = RFC()\n",
    "    abc = ABC()\n",
    "    gbc = GBC()\n",
    "\n",
    "    # Create list of model.\n",
    "    list_of_model = [\n",
    "        {\"model_name\": knn.__class__.__name__, \"model_object\": knn, \"model_id\": \"\"},\n",
    "        {\"model_name\": lgr.__class__.__name__, \"model_object\": lgr, \"model_id\": \"\"},\n",
    "        {\"model_name\": dtc.__class__.__name__, \"model_object\": dtc, \"model_id\": \"\"},\n",
    "        {\"model_name\": bgc.__class__.__name__, \"model_object\": bgc, \"model_id\": \"\"},\n",
    "        {\"model_name\": rfc.__class__.__name__, \"model_object\": rfc, \"model_id\": \"\"},\n",
    "        {\"model_name\": abc.__class__.__name__, \"model_object\": abc, \"model_id\": \"\"},\n",
    "        {\"model_name\": gbc.__class__.__name__, \"model_object\": gbc, \"model_id\": \"\"}\n",
    "    ]\n",
    "\n",
    "    return list_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec98cf5-74e2-4b0e-be39-e72a4aa991c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create hyperparameter space.\n",
    "def create_param_space():\n",
    "    \"\"\"Return a dict of model hyperparameter.\"\"\"\n",
    "\n",
    "    # Define each model hyprerparameter space.\n",
    "    knn_params = {\n",
    "        \"n_neighbors\": [2, 3, 4, 5, 6, 10, 15, 20, 25],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"p\": [1, 2]\n",
    "    }\n",
    "\n",
    "    lgr_params = {\n",
    "        \"C\": [0.01, 0.1, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "    # Hyperparameter for DTC, RFC, and GBC.\n",
    "    DEPTH = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "    # Hyperparameter for BGC, RFC, ABC, and GBC.\n",
    "    B = [10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "    \n",
    "    # Hyperparameter for ABC and GBC.\n",
    "    LR = [0.001, 0.01, 0.05, 0.1, 1]\n",
    "\n",
    "    dist_params = {\n",
    "        \"KNeighborsClassifier\": knn_params,\n",
    "        \"LogisticRegression\": lgr_params,\n",
    "        \"DecisionTreeClassifier\": {\n",
    "            \"max_depth\": DEPTH\n",
    "        },\n",
    "        \"BaggingClassifier\": {\n",
    "            \"n_estimators\": B\n",
    "        },\n",
    "        \"RandomForestClassifier\": {\n",
    "            \"n_estimators\": B,\n",
    "            \"max_depth\": DEPTH\n",
    "        },\n",
    "        \"AdaBoostClassifier\": {\n",
    "            \"n_estimators\": B,\n",
    "            \"learning_rate\": LR\n",
    "        },\n",
    "        \"GradientBoostingClassifier\": {\n",
    "            \"n_estimators\": B,\n",
    "            \"learning_rate\": LR,\n",
    "            \"max_depth\": DEPTH\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return dist_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a370c11-9d8e-450e-b67f-e46ca736dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit & tune model (do CV + HT).\n",
    "def evaluate_model(models, hyperparameters, path_log):\n",
    "    \"\"\"Cross validation & hyperparameter tuning.\"\"\"\n",
    "\n",
    "    # Load data train and valid.\n",
    "    X_train, y_train = load_data(config, \"train\")\n",
    "\n",
    "    # Create training log.\n",
    "    logger = create_training_log()\n",
    "\n",
    "    # Define a dictionary to store the trained models.\n",
    "    trained_models = {}\n",
    "\n",
    "    # For each data configuration.\n",
    "    for data_conf in X_train:\n",
    "        X_train_conf = X_train[data_conf]\n",
    "        y_train_conf = y_train[data_conf]\n",
    "        print(f\"Data Conf : {str(data_conf).upper()}\")\n",
    "        # Fit & tune each model.\n",
    "        for m, h in zip(models, hyperparameters):\n",
    "            print(f\"Fit & Tune Model : {m['model_name']}...\")\n",
    "            # Create tuner object.\n",
    "            tuner = RandomizedSearchCV(\n",
    "                estimator = m[\"model_object\"],\n",
    "                param_distributions = hyperparameters[h],\n",
    "                n_iter = 100,\n",
    "                scoring = \"f1\",\n",
    "                cv = 5,\n",
    "                return_train_score = True,\n",
    "                n_jobs = -1,\n",
    "                verbose = 1\n",
    "            )\n",
    "\n",
    "            # Compute the training time.\n",
    "            start_time = time_stamp()\n",
    "            tuner.fit(X_train_conf, y_train_conf)\n",
    "            finished_time = time_stamp()\n",
    "\n",
    "            training_time = finished_time - start_time\n",
    "            training_time = training_time.total_seconds()\n",
    "\n",
    "            # Get the model with best hyperparameters.\n",
    "            best_model = tuner.best_estimator_\n",
    "\n",
    "            # Get the scores of best model.\n",
    "            best_index = tuner.best_index_\n",
    "            train_f1 = tuner.cv_results_[\"mean_train_score\"][best_index]\n",
    "            cv_f1 = tuner.cv_results_[\"mean_test_score\"][best_index]\n",
    "\n",
    "            # Update the training log.\n",
    "            model_name = f\"{data_conf} - {m[\"model_name\"]}\"\n",
    "            logger[\"model_name\"].append(model_name)\n",
    "\n",
    "            plain_id = str(training_time)\n",
    "            cipher_id = hashlib.md5(plain_id.encode()).hexdigest()\n",
    "            logger[\"model_id\"].append(cipher_id)\n",
    "\n",
    "            logger[\"training_time\"].append(training_time)\n",
    "            logger[\"training_date\"].append(str(start_time))\n",
    "            logger[\"train_f1\"].append(train_f1)\n",
    "            logger[\"cv_f1\"].append(cv_f1)\n",
    "            logger[\"data_configuration\"].append(data_conf)\n",
    "\n",
    "            # Store the best model.\n",
    "            trained_models[model_name] = best_model\n",
    "        print()\n",
    "        \n",
    "    training_log = update_training_log(logger, path_log)\n",
    "\n",
    "    return trained_models, training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d0b23b3-6c69-4c2e-8b50-4a2f6d7c6c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Conf : UNDERSAMPLING\n",
      "Fit & Tune Model : KNeighborsClassifier...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fit & Tune Model : LogisticRegression...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fit & Tune Model : DecisionTreeClassifier...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fit & Tune Model : BaggingClassifier...\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Fit & Tune Model : RandomForestClassifier...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fit & Tune Model : AdaBoostClassifier...\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fit & Tune Model : GradientBoostingClassifier...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Data Conf : OVERSAMPLING\n",
      "Fit & Tune Model : KNeighborsClassifier...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fit & Tune Model : LogisticRegression...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fit & Tune Model : DecisionTreeClassifier...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fit & Tune Model : BaggingClassifier...\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Fit & Tune Model : RandomForestClassifier...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fit & Tune Model : AdaBoostClassifier...\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fit & Tune Model : GradientBoostingClassifier...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Data Conf : SMOTE\n",
      "Fit & Tune Model : KNeighborsClassifier...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fit & Tune Model : LogisticRegression...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fit & Tune Model : DecisionTreeClassifier...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fit & Tune Model : BaggingClassifier...\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "Fit & Tune Model : RandomForestClassifier...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Fit & Tune Model : AdaBoostClassifier...\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fit & Tune Model : GradientBoostingClassifier...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_LOG = \"../logs/training_log.json\"\n",
    "\n",
    "models = create_model_object()\n",
    "hyperparameters = create_param_space()\n",
    "\n",
    "trained_models, training_log = evaluate_model(models, hyperparameters, PATH_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7223662e-4091-4bb9-adca-ae2acd6a5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_to_df(training_log):\n",
    "    training_result = pd.DataFrame()\n",
    "\n",
    "    for log in training_log:\n",
    "        training_result = pd.concat([training_result, pd.DataFrame(log)])\n",
    "\n",
    "    training_result = training_result.sort_values(\n",
    "        [\"cv_f1\", \"training_time\"],\n",
    "        ascending = [False, True]\n",
    "    )\n",
    "\n",
    "    training_result = training_result.reset_index(drop=True)\n",
    "\n",
    "    return training_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575cf174-963b-452e-b234-17bc494fedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_result = training_log_to_df(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ed8051-5d53-4401-a532-c87fc7125588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_id</th>\n",
       "      <th>training_time</th>\n",
       "      <th>training_date</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>cv_f1</th>\n",
       "      <th>data_configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undersampling - DecisionTreeClassifier</td>\n",
       "      <td>a4149d62b97da16a889ca18f9e803df4</td>\n",
       "      <td>0.428390</td>\n",
       "      <td>2026-02-16 14:38:36.740479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling - BaggingClassifier</td>\n",
       "      <td>24c7ae353d01969179e0ccc0b30a9822</td>\n",
       "      <td>13.069867</td>\n",
       "      <td>2026-02-16 14:38:37.169201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Undersampling - GradientBoostingClassifier</td>\n",
       "      <td>67c2f1e17570839b0e787db9cb36523c</td>\n",
       "      <td>46.876801</td>\n",
       "      <td>2026-02-16 14:41:26.864004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oversampling - AdaBoostClassifier</td>\n",
       "      <td>86719065889cc71038a6101e9cc920be</td>\n",
       "      <td>78.246733</td>\n",
       "      <td>2026-02-16 14:44:36.212798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE - RandomForestClassifier</td>\n",
       "      <td>6b0f23d4e95eea49415da372572b1584</td>\n",
       "      <td>142.840787</td>\n",
       "      <td>2026-02-16 14:47:50.722258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE - GradientBoostingClassifier</td>\n",
       "      <td>47117d3e2142759f263e30f4cdbee990</td>\n",
       "      <td>133.363865</td>\n",
       "      <td>2026-02-16 14:51:45.284785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999229</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oversampling - RandomForestClassifier</td>\n",
       "      <td>1acd02cf65cc73bc702e4cdbd85b43c3</td>\n",
       "      <td>119.692405</td>\n",
       "      <td>2026-02-16 14:42:36.520149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oversampling - DecisionTreeClassifier</td>\n",
       "      <td>08d84734268b4abe6e772d263660c94b</td>\n",
       "      <td>0.402997</td>\n",
       "      <td>2026-02-16 14:42:18.351540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998844</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oversampling - BaggingClassifier</td>\n",
       "      <td>df4a1d67913b1693ce5f13612ab2b6d2</td>\n",
       "      <td>17.765183</td>\n",
       "      <td>2026-02-16 14:42:18.754742</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.998844</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE - BaggingClassifier</td>\n",
       "      <td>8b178c1239d9d3626b9c60b923480d8c</td>\n",
       "      <td>23.930947</td>\n",
       "      <td>2026-02-16 14:47:26.791088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998844</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oversampling - GradientBoostingClassifier</td>\n",
       "      <td>44e08c79b908e4df84f84b88ebc0cb3c</td>\n",
       "      <td>86.993362</td>\n",
       "      <td>2026-02-16 14:45:54.459804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998844</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SMOTE - DecisionTreeClassifier</td>\n",
       "      <td>0b75a0b27f931f3532c0a01dff29916e</td>\n",
       "      <td>0.443140</td>\n",
       "      <td>2026-02-16 14:47:26.347750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998460</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SMOTE - AdaBoostClassifier</td>\n",
       "      <td>dd07b5703bac37c93e5a8c9192575fcd</td>\n",
       "      <td>91.721145</td>\n",
       "      <td>2026-02-16 14:50:13.563318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Undersampling - AdaBoostClassifier</td>\n",
       "      <td>d02cddb1dcfe617945df60346e225f4e</td>\n",
       "      <td>58.840702</td>\n",
       "      <td>2026-02-16 14:40:28.023030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990471</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Undersampling - RandomForestClassifier</td>\n",
       "      <td>3dfe0f82d97ffb5b50b84f54e5db3181</td>\n",
       "      <td>97.783465</td>\n",
       "      <td>2026-02-16 14:38:50.239300</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.989825</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Oversampling - KNeighborsClassifier</td>\n",
       "      <td>7f46286ccb06ce8d35a0c6f71edf3e0d</td>\n",
       "      <td>4.441380</td>\n",
       "      <td>2026-02-16 14:42:13.741082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989073</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMOTE - KNeighborsClassifier</td>\n",
       "      <td>c38fc6ce47ee80cf5ceacd511c0919b1</td>\n",
       "      <td>4.713404</td>\n",
       "      <td>2026-02-16 14:47:21.453460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985144</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMOTE - LogisticRegression</td>\n",
       "      <td>8b08ed290f30f0b5e92b77d27a3a22c7</td>\n",
       "      <td>0.180545</td>\n",
       "      <td>2026-02-16 14:47:26.167079</td>\n",
       "      <td>0.976999</td>\n",
       "      <td>0.974467</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Oversampling - LogisticRegression</td>\n",
       "      <td>c769a6b8ed244d603be4e9c112777cae</td>\n",
       "      <td>0.168718</td>\n",
       "      <td>2026-02-16 14:42:18.182698</td>\n",
       "      <td>0.973072</td>\n",
       "      <td>0.968763</td>\n",
       "      <td>Oversampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Undersampling - KNeighborsClassifier</td>\n",
       "      <td>a8d4b943d0a602cacf976ba633190817</td>\n",
       "      <td>4.628762</td>\n",
       "      <td>2026-02-16 14:38:31.946477</td>\n",
       "      <td>0.964356</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Undersampling - LogisticRegression</td>\n",
       "      <td>be909e66f1f0b6a010a6094395bcfc48</td>\n",
       "      <td>0.164520</td>\n",
       "      <td>2026-02-16 14:38:36.575832</td>\n",
       "      <td>0.945468</td>\n",
       "      <td>0.940415</td>\n",
       "      <td>Undersampling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model_name  \\\n",
       "0       Undersampling - DecisionTreeClassifier   \n",
       "1            Undersampling - BaggingClassifier   \n",
       "2   Undersampling - GradientBoostingClassifier   \n",
       "3            Oversampling - AdaBoostClassifier   \n",
       "4               SMOTE - RandomForestClassifier   \n",
       "5           SMOTE - GradientBoostingClassifier   \n",
       "6        Oversampling - RandomForestClassifier   \n",
       "7        Oversampling - DecisionTreeClassifier   \n",
       "8             Oversampling - BaggingClassifier   \n",
       "9                    SMOTE - BaggingClassifier   \n",
       "10   Oversampling - GradientBoostingClassifier   \n",
       "11              SMOTE - DecisionTreeClassifier   \n",
       "12                  SMOTE - AdaBoostClassifier   \n",
       "13          Undersampling - AdaBoostClassifier   \n",
       "14      Undersampling - RandomForestClassifier   \n",
       "15         Oversampling - KNeighborsClassifier   \n",
       "16                SMOTE - KNeighborsClassifier   \n",
       "17                  SMOTE - LogisticRegression   \n",
       "18           Oversampling - LogisticRegression   \n",
       "19        Undersampling - KNeighborsClassifier   \n",
       "20          Undersampling - LogisticRegression   \n",
       "\n",
       "                            model_id  training_time  \\\n",
       "0   a4149d62b97da16a889ca18f9e803df4       0.428390   \n",
       "1   24c7ae353d01969179e0ccc0b30a9822      13.069867   \n",
       "2   67c2f1e17570839b0e787db9cb36523c      46.876801   \n",
       "3   86719065889cc71038a6101e9cc920be      78.246733   \n",
       "4   6b0f23d4e95eea49415da372572b1584     142.840787   \n",
       "5   47117d3e2142759f263e30f4cdbee990     133.363865   \n",
       "6   1acd02cf65cc73bc702e4cdbd85b43c3     119.692405   \n",
       "7   08d84734268b4abe6e772d263660c94b       0.402997   \n",
       "8   df4a1d67913b1693ce5f13612ab2b6d2      17.765183   \n",
       "9   8b178c1239d9d3626b9c60b923480d8c      23.930947   \n",
       "10  44e08c79b908e4df84f84b88ebc0cb3c      86.993362   \n",
       "11  0b75a0b27f931f3532c0a01dff29916e       0.443140   \n",
       "12  dd07b5703bac37c93e5a8c9192575fcd      91.721145   \n",
       "13  d02cddb1dcfe617945df60346e225f4e      58.840702   \n",
       "14  3dfe0f82d97ffb5b50b84f54e5db3181      97.783465   \n",
       "15  7f46286ccb06ce8d35a0c6f71edf3e0d       4.441380   \n",
       "16  c38fc6ce47ee80cf5ceacd511c0919b1       4.713404   \n",
       "17  8b08ed290f30f0b5e92b77d27a3a22c7       0.180545   \n",
       "18  c769a6b8ed244d603be4e9c112777cae       0.168718   \n",
       "19  a8d4b943d0a602cacf976ba633190817       4.628762   \n",
       "20  be909e66f1f0b6a010a6094395bcfc48       0.164520   \n",
       "\n",
       "                 training_date  train_f1     cv_f1 data_configuration  \n",
       "0   2026-02-16 14:38:36.740479  1.000000  1.000000      Undersampling  \n",
       "1   2026-02-16 14:38:37.169201  1.000000  1.000000      Undersampling  \n",
       "2   2026-02-16 14:41:26.864004  1.000000  1.000000      Undersampling  \n",
       "3   2026-02-16 14:44:36.212798  1.000000  1.000000       Oversampling  \n",
       "4   2026-02-16 14:47:50.722258  1.000000  0.999613              SMOTE  \n",
       "5   2026-02-16 14:51:45.284785  1.000000  0.999229              SMOTE  \n",
       "6   2026-02-16 14:42:36.520149  1.000000  0.999228       Oversampling  \n",
       "7   2026-02-16 14:42:18.351540  1.000000  0.998844       Oversampling  \n",
       "8   2026-02-16 14:42:18.754742  0.999711  0.998844       Oversampling  \n",
       "9   2026-02-16 14:47:26.791088  1.000000  0.998844              SMOTE  \n",
       "10  2026-02-16 14:45:54.459804  1.000000  0.998844       Oversampling  \n",
       "11  2026-02-16 14:47:26.347750  1.000000  0.998460              SMOTE  \n",
       "12  2026-02-16 14:50:13.563318  1.000000  0.998095              SMOTE  \n",
       "13  2026-02-16 14:40:28.023030  1.000000  0.990471      Undersampling  \n",
       "14  2026-02-16 14:38:50.239300  0.998340  0.989825      Undersampling  \n",
       "15  2026-02-16 14:42:13.741082  1.000000  0.989073       Oversampling  \n",
       "16  2026-02-16 14:47:21.453460  1.000000  0.985144              SMOTE  \n",
       "17  2026-02-16 14:47:26.167079  0.976999  0.974467              SMOTE  \n",
       "18  2026-02-16 14:42:18.182698  0.973072  0.968763       Oversampling  \n",
       "19  2026-02-16 14:38:31.946477  0.964356  0.951336      Undersampling  \n",
       "20  2026-02-16 14:38:36.575832  0.945468  0.940415      Undersampling  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9ce8d-5b99-4d19-9df3-e9b1d7f22ac3",
   "metadata": {},
   "source": [
    "## **5 - Model Serialization**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3cfd30b-9380-40a9-8be5-3ba8ce9f5ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the best model.\n",
    "best = \"Undersampling - DecisionTreeClassifier\"\n",
    "best_model = trained_models[best]\n",
    "\n",
    "PATH_PRODUCTION_MODEL = \"../models/best_model.pkl\"\n",
    "joblib.dump(best_model, PATH_PRODUCTION_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e229cf-3835-4c40-8da2-15e4ba1fb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Updated! \n",
      "Key: path_production_model \n",
      "Value: ../models/best_model.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the configuration parameter.\n",
    "config = update_config(\n",
    "    key = \"path_production_model\",\n",
    "    value = PATH_PRODUCTION_MODEL,\n",
    "    params = config,\n",
    "    path_config = PATH_CONFIG\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
